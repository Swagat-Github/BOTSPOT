{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries:\n",
    "### Install the modules which we will be using in this project "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install speechrecognition pyttsx3 googletrans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr\n",
    "import pyttsx3\n",
    "from googletrans import Translator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Speech Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Recognizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = sr.Recognizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If you get an error \"Microsoft Visual C++ 14.0 is required\" or \"PyAudio module not found\" then follow the steps in README.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute only if you get an error above\n",
    "# !pip install PyAudio-0.2.11-cp38-cp38-win_amd64.whl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define your microphone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the following comment to see your input devices\n",
    "# print(sr.Microphone.list_microphone_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mic = sr.Microphone()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recognize Speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnknownValueError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnknownValueError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m    r\u001b[38;5;241m.\u001b[39madjust_for_ambient_noise(source) \n\u001b[0;32m      3\u001b[0m    audio \u001b[38;5;241m=\u001b[39m r\u001b[38;5;241m.\u001b[39mlisten(source) \n\u001b[1;32m----> 4\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecognize_google\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\speech_recognition\\__init__.py:858\u001b[0m, in \u001b[0;36mRecognizer.recognize_google\u001b[1;34m(self, audio_data, key, language, show_all)\u001b[0m\n\u001b[0;32m    856\u001b[0m \u001b[38;5;66;03m# return results\u001b[39;00m\n\u001b[0;32m    857\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m show_all: \u001b[38;5;28;01mreturn\u001b[39;00m actual_result\n\u001b[1;32m--> 858\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(actual_result, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(actual_result\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malternative\u001b[39m\u001b[38;5;124m\"\u001b[39m, [])) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m: \u001b[38;5;28;01mraise\u001b[39;00m UnknownValueError()\n\u001b[0;32m    860\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfidence\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m actual_result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malternative\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m    861\u001b[0m     \u001b[38;5;66;03m# return alternative with highest confidence score\u001b[39;00m\n\u001b[0;32m    862\u001b[0m     best_hypothesis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(actual_result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malternative\u001b[39m\u001b[38;5;124m\"\u001b[39m], key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m alternative: alternative[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfidence\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "\u001b[1;31mUnknownValueError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with mic as source: \n",
    "   r.adjust_for_ambient_noise(source) \n",
    "   audio = r.listen(source) \n",
    "result = r.recognize_google(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want to see your result, execute the following\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the Translator\n",
    "## Define Translator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Translator() \n",
    "k = p.translate(result, dest='spanish')\n",
    "# you can put any language in the destination attribute, I have used spanish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we convert the translated result into a text format\n",
    "translated = str(k.text)\n",
    "print(translated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text to Speech Engine\n",
    "## Define Text to Speech Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = pyttsx3.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the language of the translator\n",
    "#Here is the code to see the list of languages and their IDs, which we will need when we are defining the translator.\n",
    "#It is recommended to run this code before going to the next step.\n",
    "engine = pyttsx3.init() \n",
    "voices = engine.getProperty('voices') \n",
    "for voice in voices: \n",
    "  print(\"Voice:\") \n",
    "  print(\" - ID: %s\" % voice.id) \n",
    "  print(\" - Name: %s\" % voice.name) \n",
    "  print(\" - Languages: %s\" % voice.languages) \n",
    "  print(\" - Gender: %s\" % voice.gender) \n",
    "  print(\" - Age: %s\" % voice.age)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the speaker language\n",
    "### Copy the ID of the language that you want to use from the above code and paste it into your program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here I have used ID from my machine. Please use your ID in this code\n",
    "fr_voice_id = \"HKEY_LOCAL_MACHINE\\SOFTWARE\\Microsoft\\Speech\\Voices\\Tokens\\TTS_MS_EN-US_ZIRA_11.0\" \n",
    "engine.setProperty('voice', fr_voice_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output the voice by the following\n",
    "engine.say(translated)\n",
    "engine.runAndWait()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
